{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaptainZeroX/CaptainZeroX.github.io/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "2d651c59-770e-4eca-da8f-ba8d9a028fe2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 31 21:33:02 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "5d516ace-75eb-4383-c398-fb4f17a806d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Car Automation 2. Security footage 3.facial recognition"
      ],
      "metadata": {
        "id": "VyWRkvWGbCXj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#when the model learns the patterns of the training but preforms poorly on the test data"
      ],
      "metadata": {
        "id": "d1rxD6GObCqh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.Hold-out (data) 2.Cross-validation(data) 3.Feature Selection\n",
        "# 1. splitting data saet to training and testing 80% traind and 20% test it rquires large data set\n",
        "# 2. split data into k groups, one group be test set (similat to holde out) and the others are training set and repeat process for each individual in the group. it is much computationally expensive but better than hold out\n",
        "# 3. limited data set with large features, we select most important featur to train this doesnt allow over fitting , we can use individual models to train for every feature to avoid over fitting and evaluate generalized capabilities"
      ],
      "metadata": {
        "id": "ocvOdWKcbEKr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98efa15-e7ab-42f3-ddd0-310868d30480"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 454kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.65MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.28MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfZy5_YN3QxG",
        "outputId": "b230e54d-c26f-4020-ec0b-4ea50e9cfe75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]"
      ],
      "metadata": {
        "id": "xA198VL-6XYF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9CQShzL3klI",
        "outputId": "d7e0657d-40a5-4346-9f15-ee431c21727e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0 - zero': 0,\n",
              " '1 - one': 1,\n",
              " '2 - two': 2,\n",
              " '3 - three': 3,\n",
              " '4 - four': 4,\n",
              " '5 - five': 5,\n",
              " '6 - six': 6,\n",
              " '7 - seven': 7,\n",
              " '8 - eight': 8,\n",
              " '9 - nine': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdFFNXT43mOo",
        "outputId": "47247d4c-498c-41c0-9ff7-2472cd2cf1ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 5)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image, label = train_data[0]\n",
        "print(image.shape)\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "4deb8e96-2832-457e-a072-0ff98b405c5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 27.5, 27.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 1,5\n",
        "for i in range(1, rows*cols+1):\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "    image, label = train_data[random_idx]\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "rpmzGjfQ6ulH",
        "outputId": "96aad74b-89a2-4a6a-9d9a-5457a2056603"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pod4hV07hG4",
        "outputId": "4fa0aa23-98e2-40ce-f158-51850859e4c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "image, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"off\")\n",
        "print(f\"Image shape: {image.shape}\\nLabel shape: {label.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "ml6P2uyg7nFM",
        "outputId": "dd22d3dd-9da3-4e3d-a117-d1296252bc4f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28])\n",
            "Label shape: torch.Size([])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a flatten layer\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "#  get a single samplw\n",
        "x= train_features_batch[0]\n",
        "print(f\"Shape before flattening: {x.shape}\")\n",
        "output = flatten_model(x) # forward pass\n",
        "print(f\"Shape after flattening: {flatten_model(x).shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNF8yk67-eL0",
        "outputId": "11c5881a-50e6-4b47-8db9-41d3f3c50960"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before flattening: torch.Size([1, 28, 28])\n",
            "Shape after flattening: torch.Size([1, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTModelV0(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,out_channels=hidden_units, kernel_size=3,stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3,stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,out_channels=hidden_units, kernel_size=3,stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3,stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=hidden_units*7*7, out_features=output_shape)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block_1(x)\n",
        "        #print(f\"Output shape of conv_block_1:{x.shape}\")\n",
        "        x = self.conv_block_2(x)\n",
        "        #print(f\"Output shape of conv_block_2:{x.shape}\")\n",
        "        x = self.classifier(x)\n",
        "       #print(f\"Output shape of classifier:{x.shape}\")\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZrB-rem9oom",
        "outputId": "d9cd7b47-27ef-4d8e-a5b4-17e412fdd4a4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTModelV0(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(784, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(784, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "#Define hyper parameters\n",
        "model_0 = MNISTModelV0(\n",
        "    input_shape=1, ## since the color channel is only one color\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "2z_DO5gcSjKq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Accuracy function\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n"
      ],
      "metadata": {
        "id": "YWfGYBND9AWQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimization function\n",
        "optimizer = torch.optim.SGD(model_0.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "JpS6gQgP9JZR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device=device):\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "          # Make our data device agnostic\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            # Make predictions\n",
        "            y_pred = model(X)\n",
        "\n",
        "\n",
        "            loss+= loss_fn(y_pred, y)\n",
        "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "        # Scale loss and acc to find the average loss/acc per batch\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "    return{\"model_name\": model.__class__.__name__,\n",
        "           \"model_loss\": loss.item(),\n",
        "           \"model_acc\": acc}\n",
        "\n",
        "# calaculate model 0 results\n",
        "model_0_results = eval_model(model=model_0,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn)\n",
        "model_0_results\n",
        "\n"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "16c56922-0803-4bae-e432-b0d5351da2f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MNISTModelV0' object has no attribute 'layer_stack'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3c32ce4148b4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# calaculate model 0 results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m model_0_results = eval_model(model=model_0,\n\u001b[0m\u001b[1;32m     31\u001b[0m                              \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                              \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-3c32ce4148b4>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model, data_loader, loss_fn, accuracy_fn, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-6e02edd96b24>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNISTModelV0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MNISTModelV0' object has no attribute 'layer_stack'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RniJaJhYX3F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}